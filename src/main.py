# -*- coding: utf-8 -*-
"""dataMiningProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bZxs4vyFBZpJeVneJTvoUgkj8vOXQg_F

**Airline Passenger Satisfaction**

Author: Ozan GEÇKİN

In this project, Feature Engineering, Feature Selection and Classification processes were performed on the dataset containing the satisfaction surveys of an airline company.

The aim of the project is to estimate the satisfaction status. Anticipating this situation gives the airline a great help in improving its services.

In this project, Random Forest, Logistic Regression, XGB, Gaussian Navie Bayes(I implemented) as classicifation techniques

I made the accurancy account with roc_auc_score and also used other indicators. You can observe the accurancy difference between these 4 classification algorithms at the bottom of the project.
"""

import numpy as np
import pandas as pd
!pip install plotly==4.8.2
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import math
from sklearn.metrics import f1_score,confusion_matrix, roc_auc_score, accuracy_score, plot_confusion_matrix, classification_report,plot_roc_curve
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb

import warnings
warnings.filterwarnings('ignore')

"""**Description of the dataset attributes used in the project.**

*Gender*: Gender of the passengers (Female, Male)

*Customer Type*: The customer type (Loyal customer, disloyal customer)

*Age*: The actual age of the passengers

*Type of Travel*: Purpose of the flight of the passengers (Personal Travel, Business Travel)

*Class*: Travel class in the plane of the passengers (Business, Eco, Eco Plus)

*Flight distance*: The flight distance of this journey

*Inflight wifi service*: Satisfaction level of the inflight wifi service (0:Not Applicable;1-5)

*Departure/Arrival time convenient*: Satisfaction level of Departure/Arrival time convenient

*Ease of Online booking*: Satisfaction level of online booking

*Gate location*: Satisfaction level of Gate location

*Food and drink*: Satisfaction level of Food and drink

*Online boarding*: Satisfaction level of online boarding

*Seat comfort*: Satisfaction level of Seat comfort

*Inflight entertainment*: Satisfaction level of inflight entertainment

*On-board service*: Satisfaction level of On-board service

*Leg room service*: Satisfaction level of Leg room service

*Baggage handling*: Satisfaction level of baggage handling

*Check-in service*: Satisfaction level of Check-in service

*Inflight service*: Satisfaction level of inflight service

*Cleanliness*: Satisfaction level of Cleanliness

*Departure Delay in Minutes*: Minutes delayed when departure

*Arrival Delay in Minutes*: Minutes delayed when Arrival

*Satisfaction*: Airline satisfaction level(Satisfaction, neutral or dissatisfaction)
"""

dftrain = pd.read_csv('/content/drive/MyDrive/dataminigproje/train.csv')
dftest = pd.read_csv("/content/drive/MyDrive/dataminigproje/test.csv")
dftrain.head(5)

"""I'll start with removing the Unnamed and id column. Cause my guess is they don't matter

"""

dftrain= dftrain.drop(["Unnamed: 0","id"],axis=1)
dftest = dftest.drop(["Unnamed: 0","id"],axis=1)

"""I'm merging the data because I'm going to do cleaning and parameter selection on the data."""

df = dftrain.append(dftest)

fig = px.sunburst(df, path=['Type of Travel','Class', 'Customer Type'],color_continuous_scale='RdBu')
fig.show()

dftrain.describe()

plt.figure(figsize=(28,12))
sns.boxplot(dftrain['Flight Distance'])
plt.show()
plt.figure(figsize=(28,12))
sns.boxplot(dftest['Flight Distance'])
plt.show()

# Removing the outliers
def removeOutliers(data, col):
    Q3 = np.quantile(data[col], 0.75)
    Q1 = np.quantile(data[col], 0.25)
    IQR = Q3 - Q1
 
    print("IQR value for column %s is: %s" % (col, IQR))
    global outlier_free_list
    global filtered_data
 
    lower_range = Q1 - 1.5 * IQR
    upper_range = Q3 + 1.5 * IQR
    outlier_free_list = [x for x in data[col] if (
        (x > lower_range) & (x < upper_range))]
    filtered_data = data.loc[data[col].isin(outlier_free_list)]
   

removeOutliers(dftrain, "Flight Distance")
dftrain=filtered_data

removeOutliers(dftest, "Flight Distance")
dftest=filtered_data

dftrain

plt.figure(figsize=(28,12))
sns.boxplot(dftrain['Flight Distance'])
plt.figure(figsize=(28,12))
sns.boxplot(dftest['Flight Distance'])

"""İmputation"""

print(dftrain.isnull().sum())

print(dftest.isnull().sum())

df.head()

df.info()

"""Imputasyon, (Encoding),(Missing Values)

Based on the training data above, there are a few things we need to do to prepare the data for use in a model. There are several categorical variables that need to be coded, including our target variable 'Satisfaction'.
"""

def transform_gender(x):
    if x == 'Female':
        return 1
    elif x == 'Male':
        return 0
    else:
        return -1
    
def transform_customer_type(x):
    if x == 'Loyal Customer':
        return 1
    elif x == 'disloyal Customer':
        return 0
    else:
        return -1
    
def transform_travel_type(x):
    if x == 'Business travel':
        return 1
    elif x == 'Personal Travel':
        return 0
    else:
        return -1
    
def transform_class(x):
    if x == 'Business':
        return 2
    elif x == 'Eco Plus':
        return 1
    elif x == 'Eco':
        return 0    
    else:
        return -1
    
def transform_satisfaction(x):
    if x == 'satisfied':
        return 1
    elif x == 'neutral or dissatisfied':
        return 0
    else:
        return -1

def process_data(df):
    df['Gender']=df['Gender'].apply(transform_gender)
    df['Customer Type'] = df['Customer Type'].apply(transform_customer_type)
    df['Type of Travel'] = df['Type of Travel'].apply(transform_travel_type)
    df['Class'] = df['Class'].apply(transform_class)
    df['satisfaction'] = df['satisfaction'].apply(transform_satisfaction)
    df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median(), inplace = True)
    return df

train=process_data(dftrain)
test=process_data(dftest)
train.head()

plt.figure(figsize = (26,10))
dftrain.corr(method='pearson')['satisfaction'].sort_values().plot(kind='bar')

"""As you can see, the correlation value of the first 5 values is low, I delete them."""

dftrain=dftrain.drop(columns=["Arrival Delay in Minutes","Departure/Arrival time convenient","Departure Delay in Minutes","Gender","Gate location"],axis=1)
dftest=dftest.drop(columns=["Arrival Delay in Minutes","Departure/Arrival time convenient","Departure Delay in Minutes","Gender","Gate location"],axis=1)

"""Normalization"""

X_train=dftrain.drop("satisfaction",axis=1)
X_test=dftest.drop("satisfaction",axis=1)
target = ['satisfaction']
y_train = dftrain[target].to_numpy()
y_test = dftest[target].to_numpy()

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

"""I am doing a correlation matrix, I learn more about data, I learn the relationship between parameters

"""

plt.figure(figsize = (28,12))
sns.set_context('poster',font_scale=1)
sns.heatmap(dftrain.corr(), annot = True).set_title('Params')

"""Scaler process complete. Let's take a look at a correlation heatmap to see which attributes correlate well with customer satisfaction.

**Best features** - Online Booking, Class, and Type of Travel

**Worst features** - Age, Customer Type, and Ease of Online booking

"""

plt.figure(figsize=(28,12))
sns.histplot(x='Age',hue="satisfaction",data=train,kde=True,palette="mako")
plt.figure(figsize=(28,12))
sns.countplot(x='Online boarding',hue="satisfaction",data=train,color="blue")
plt.figure(figsize=(28,12))
sns.countplot(x='Customer Type',hue="satisfaction",data=train)
plt.figure(figsize=(28,12))
sns.countplot(x='Inflight wifi service',hue="satisfaction",data=train,color="blue")
plt.figure(figsize=(28,12))
sns.countplot(x='Food and drink',hue="satisfaction",data=train,color="orange")

"""We will try a few different models to see which one is the best choice for our problem.

Below I have created a small function that will train, predict and evaluate all of our models.

We will evaluate the performance of our models with the ROC_AUC metric, Confusion Matrix, F1 Score (F1 Score).
These metrics are good for classifying a relatively balanced dataset for our purpose. We will also look at the confusion matrix of our model to best understand how our model mischaracterizes the predictions.
"""

def run_and_model(model, X_train, y_train, X_test, y_test):
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    roc_auc = roc_auc_score(y_test, y_pred)
    print("ROC_AUC = {}".format(roc_auc))
    print(classification_report(y_test,y_pred,digits=5))
    plot_confusion_matrix(model, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')
    
    return model, roc_auc

"""**Navie Bayes Implementation**"""

class NaiveBayes():

  def fit(self, X_train, y_train):
    self.X_train,self.y_train = X_train, y_train
    self.classes = np.unique(y_train)
    self.param=[]
    for i in range(2):
      self.param.append([])
      for row in X_train:
        param={"mean":row.mean(),"var":row.var()}
        self.param[i].append(param)

  def callikehood(self, mean, var, x):
    eps = 1e-4 
    coeff = 1.0 / math.sqrt(2.0 * math.pi * var + eps)
    exponent = math.exp(-(math.pow(x - mean, 2) / (2 * var + eps)))
    return coeff * exponent

  def calPrior(self, c):
    fr = np.mean(self.y_train == c)
    return fr

  def classify(self,model):
      posts = []
      for i, c in enumerate(self.classes):
          post = self.calPrior(c)
          for attributeVal, params in zip(model, self.param[i]):
              possible = self.callikehood(params["mean"], params["var"], attributeVal)
              post *= possible
          posts.append(post)
      return self.classes[np.argmax(posts)]

  def predict(self, X_test):
    y_pred = [self.classify(model) for model in X_test]
    return y_pred

clf= NaiveBayes()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
roc_auc_nb = roc_auc_score(y_test, y_pred)
print("ROC_AUC = {}".format(roc_auc_nb))
print(classification_report(y_test,y_pred,digits=5))

"""**Random Forest**"""

params_rf = {'max_depth': 25,
         'min_samples_leaf': 1,
         'min_samples_split': 2,
         'n_estimators': 1200,
         'random_state': 42}

model_rf = RandomForestClassifier(**params_rf)
model_rf, roc_auc_rf = run_and_model(model_rf, X_train, y_train, X_test, y_test)

"""**Logistic Regression**"""

model_lr = LogisticRegression(max_iter=10000)
model_lr, roc_auc_lr = run_and_model(model_lr, X_train, y_train, X_test, y_test)

model_xgb= xgb.XGBClassifier()
model_xgb,roc_auc_xgb=run_and_model(model_xgb, X_train, y_train, X_test, y_test)

aucScore = [roc_auc_nb, roc_auc_rf, roc_auc_lr, roc_auc_xgb]
modelScores = pd.DataFrame(aucScore, index=['Navie Bayes','Random Forest','Logistic Regression','XGBoost'],columns=['ACC'])
modelScores.head()